Ryo Kamoi is a Ph.D. student at Penn State University, advised by Dr. [Rui Zhang](https://ryanzhumich.github.io/). He is broadly interested in Natural Language Processing, with a specific focus on:

* Inference-time scaling, detecting and mitigating errors in LLM Responses
* Fact-checking, factuality evaluation, and textual entailment
* Vision-language models

[[Personal Website](https://ryokamoi.github.io/)] [[Google Scholar](https://scholar.google.com/citations?user=4OWTLKAAAAAJ)] [[Semantic Scholar](https://www.semanticscholar.org/author/Ryo-Kamoi/83757854)]

## Evaluation Datasets

### Text

* ReaLMistake [[huggingface dataset](https://huggingface.co/datasets/ryokamoi/realmistake)] [[code](https://github.com/psunlpgroup/ReaLMistake)]
  * Paper: [Evaluating LLMs at Detecting Errors in LLM Responses](https://arxiv.org/abs/2404.03602) (COLM 2024)
  * Benchmark for evaluating error detection methods that detect mistakes in LLM responses
  * Expert error annotations on responses from GPT-4 and Llama 2 70B on three tasks

* WiCE [[dataset and code](https://github.com/ryokamoi/wice)]
  * Paper: [WiCE: Real-World Entailment for Claims in Wikipedia](https://arxiv.org/abs/2303.01432) (EMNLP2023)
  * Dataset for document-level NLI
  * Fine-grained textual entailment dataset built on pairs of natural claims and evidence extracted from Wikipedia

### Vision-language

* VisOnlyQA [[project website](https://visonlyqa.github.io/)] [[huggingface dataset](https://huggingface.co/collections/ryokamoi/visonlyqa-674e86c7ec384b629bb97bc3)] [[code](https://github.com/psunlpgroup/VisOnlyQA)]
  * Paper: [VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information](https://arxiv.org/abs/2412.00947)
  * Dataset for evaluating visual perception capabilities of LVLMs on geometric and numerical information about scientific figures

## Survey

* [When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs](https://arxiv.org/abs/2406.01297) (TACL 2024)
  * Paper list on self-correction of LLMs: [https://github.com/ryokamoi/llm-self-correction-papers](https://github.com/ryokamoi/llm-self-correction-papers)

## Other Resources

* Shortcomings of Question Answering Based Factuality Frameworks for Error Localization [[human annotation](https://github.com/ryokamoi/QA-metrics-human-annotation)]
  * Paper: [Shortcomings of Question Answering Based Factuality Frameworks for Error Localization](https://aclanthology.org/2023.eacl-main.11/) (EACL2023)

<!--
**ryokamoi/ryokamoi** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
